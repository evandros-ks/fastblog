{
  
    
        "post0": {
            "title": "Tabu Search",
            "content": "Tabu Search . Tabu Search is a meta-heuristic optimization algorithm leveraging local search strategies and memory structures. Since local search has the tendency to get stuck in local optima, it uses memory structures to help escape these optima by using an explorative strategy and avoiding previously visited nodes. The idea of prohibiting previously visited nodes is where the name tabu comes from. . Local Search . The first main concept we&#39;ll go over is the idea of Local Search. In Local Search, we start with an initial viable solution and generate a set of neighbouring solutions. We then iterate through each solution of the set and continue the next iteration with the best neighbouring solution. We continue this algorithm until our termination criteria is met. . def generate_first_solution(*args): pass def generate_neighbourhood(*args): pass def objective_function(*args): pass def check_termination_criteria(*args): pass current_solution = generate_first_solution() termination_criteria = False while not termination_criteria: # initialize best neighbouring objective value and generate neighbours best_n_objective_val = objective_function(current_solution) neighbours = generate_neighbourhood(current_solution) # iterate each neighbour for n in neighbours: current_objective_val = objective_function(n) # find the best neighbour objective value to use for the next iteration # we&#39;re assuming we want to minimize the objective value in this scenario if current_objective_val &lt; best_n_objective_val: best_n_objective_val = current_objective_val current_solution = n # check if termination criteria has been met yet if check_termination_criteria(): termination_criteria = True . Although this approach is quite straightforward and quick to implement, it comes with its pitfalls. In some cases, it becomes computationally expensive to search through all the possible neighbours of the current solution. On the other hand, considering only the immediate neighbours yields a very limited horizon and is also not efficient. This makes our algorithm susceptible to being stuck in local optima based on our neighbourhood generation. The difference between local and global optima convergence can be seen in the example below. . Memory . In order to avoid the pitfall of local optima, Tabu Search incorporates two different memory structures. Short-term memory is based on the recency of occurrence to avoid previously visited solutions. This short-term structure could also be used to tabulate viable solutions and intensify the search at these solutions. Long-term memory is based on the frequency of occurrence starting from the beginning of the optimization. By keeping track of frequently visited solutions, it can diversify the search space by avoiding frequently visited solutions. . The short-term memory component is formerly known as the Tabu List or intensification. This structure stores a fixed and limited number of solutions for a number of iterations, $T$, also known as the Tabu Tenure. . The long-term memory component stores the frequency of occurrence and is also referred to as diversification. Although Tabu Lists are useful to locally optimize the best known solution, it may be too local in its approach and miss good unexplored solutions. Diversification overcomes this problem through two main approaches: . Restart Diversification: Restart search space at unexplored solutions | Continuous Diversification: Penalizing the objective function through a frequency-memory term of the current solution | . Tabu Tenure . As previously mentioned, the Tabu Tenure defines the size of the Tabu List. This proves to be an important parameter for Tabu Search since it&#39;s responsible for helping the search escape local optima. If these search spaces are bigger than the Tabu Tenure our method would not be able to escape these cycles. Two main methods are proposed for defining this parameter: . Static: Select $T$ as a constant value ($ sqrt{n}$ problem size) | Dynamic: Random: Select $T$ to vary randomly between $T_{min}$ and $T_{max}$ | Systemic: Select a sequence of tenure values $T$ that is repeated throughout the search | Time-dependent: Tabu tenure progressively decreases according to time or number of iterations in order to gradually reduce diversification level | . | . Aspiration Criteria . An optional component of Tabu Search is the use of an Aspiration Criteria. This allows a move to be made even if it&#39;s in the Tabu List which helps prevent stagnation. Common examples of Aspiration Criteria include: . if the move yields a better solution than any solution obtained so far | if the move yields a better solution than an aspiration value (defined depending on optimization problem) | if the direction of the search (improving or non-improving) does not change | . Termination Criteria . After completing an iteration cycle, the algorithm must check if any termination criteria has been met yet. These stopping conditions include: . Evidence shows that the optimal solution has been found | No feasible solutions in current neighbourhood generation | Completed the maximum number of iterations | An improved solution hasn&#39;t been found in a specified number of iterations | . Algorithm . Choose an initial solution $s$ in $X$ for the first iteration $k=1$ | Generate neighbouring solutions $V^{*} subseteq N(s,k) $ for the current solution $s$ and iteration $k$ | Select the best solution $s&#39;$ in our current neighbourhood $V^{*}$ that&#39;s not tabu $T(s)$ or that meets our aspiration criteria $A(s)$ | Update Tabu List $T(s)$ by removing each solution past the Tabu Tenure, incrementing each counter, and adding our current solution $s&#39;$ | If the termination criteria are met stop the search else continue from step 2 with our best neighbourhood solution $s&#39;$ | More formally we can describe the selection of the best solution $s&#39;$ for iteration $k$ with the following set relation: . $s&#39; in N(s,k) = {N(s,k) - T(s,k) } + A(s,k)$ . Code . import math def generate_first_solution(): pass def generate_neighbourhood(): pass def objective_function(): pass def check_termination_criteria(): pass neighbourhood_solution = generate_first_solution() termination_criteria = False k = 0 # iteration cycle tabu_list = {neighbourhood_solution: 1} tabu_tenure = int(math.sqrt(100)) # CHANGE best_solution = neighbourhood_solution best_objective_val = math.inf while not termination_criteria: # update iteration k += 1 # initialize best neighbouring objective value and generate neighbours neighbourhood_objective_val = objective_function(neighbourhood_solution) neighbours = generate_neighbourhood(neighbourhood_solution) # iterate each neighbour for n in neighbours: current_objective_val = objective_function(n) # find the best neighbour objective value that is not tabu # we&#39;re assuming we want to minimize the objective value in this scenario if (n not in tabu_list) and (current_objective_val &lt; neighbourhood_objective_val): neighbourhood_objective_val = current_objective_val neighbourhood_solution = n # aspiration criteria (best solution obtained so far) if current_objective_val &lt; best_objective_val: best_objective_val = current_objective_val best_solution = n # update tabu list for k,v in list(tabu_list.items()): tabu_list[k] += 1 if tabu_list[k] == tabu_tenure: del tabu_list[k] # add best neighbourhood solution to tabu list tabu_list[current_solution] = 1 # check if termination criteria has been met yet if check_termination_criteria(): termination_criteria = True . Travelling Salesman Problem . The travelling salesman problem is a commonly studied optimization problem that tries to optimize the shortest possible route when visiting a list of $n$ cities. In the figure below, we have an example scenario where we&#39;re trying to find the shortest route. Each destination is denoted as point in the figure. . import matplotlib.pyplot as plt import random random.seed(42) num_cities = 12 coordinates = [(round(random.uniform(0, 10), 2), round(random.uniform(0, 10), 2)) for _ in range(num_cities)] coordinates = coordinates + [coordinates[0]] plt.scatter(*zip(*(coordinates))) plt.title(&#39;Coordinates of Cities&#39;) plt.xlabel(&#39;X Coordinate&#39;) plt.ylabel(&#39;Y Coordinate&#39;) plt.show() . Search Space . When visiting relatively few cities, it&#39;s tangible in finding an optimal solution. However, it becomes quite unfeasible the more cities you visit. For $n$ destinations, we can derive a total of $ frac{(n-1)!}{2}$ possible routes. . n Number of paths Time (1 μs/chemin) . 5 | $12$ | $12$ μs | . 10 | $181,440$ | $0.18$ s | . 15 | $4.359 times 10^{10}$ | $12$ h | . 20 | $6.082 times 10^{16}$ | $1,928$ years | . 61 | $4.160 times 10^{81}$ | $13.19 times 10^{67}$ years | . Possible Moves . In this example, there are a limited number of moves given each state $s$. Since we have a total of $n$ cities and only perform one swap at a time, we have ${n choose 2}$ (n choose 2) number of swaps, or: . ${n choose 2} = frac{n!}{(n-2)!2!}$ . For example, let&#39;s say we have 4 possible cities - the possible swaps would be the following combinations where we would be swapping the order of cities we visit. . [(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)] . Objective Function . In this example, we can set our objective function as the total Euclidean distance travelled. Other distance measures could also be used. . def find_distance(c1, c2): return ((c1[0] - c2[0])**2 + (c1[1] - c2[1])**2)**(1/2) def find_total_distance(coordinates): total_distance = 0 for i in range(1, len(coordinates)): total_distance += find_distance(coordinates[i-1], coordinates[i]) return total_distance . $ textrm{Distance} = sqrt{(x_{2}-x_{1})^{2} + (y_{2}-y_{1})^{2}}$ . def objective_fn(coordinates): return find_total_distance(coordinates) . Here we can see the route of a randomly generated path. It&#39;s clearly not optimized, let&#39;s see if our Tabu Search can solve it! . import matplotlib.pyplot as plt import random random.seed(42) num_cities = 12 coordinates = [(round(random.uniform(0, 10), 2), round(random.uniform(0, 10), 2)) for _ in range(num_cities)] coordinates = coordinates + [coordinates[0]] plt.scatter(*zip(*(coordinates))) plt.plot(*zip(*(coordinates))) plt.title(&#39;Coordinates of Cities&#39;) plt.xlabel(&#39;X Coordinate&#39;) plt.ylabel(&#39;Y Coordinate&#39;) plt.show() . Code . import ast import itertools import math import matplotlib.pyplot as plt import random def generate_first_solution(num_cities, seed=42): # initialize seed for coordinates to be consistent random.seed(seed) # generate 0,10 grid coordinates = [(round(random.uniform(0, 10), 2), round(random.uniform(0, 10), 2)) for _ in range(num_cities)] # append first destination since we want to end there coordinates = coordinates + [coordinates[0]] return coordinates def swap_coordinates(coordinates, swap): c1, c2 = swap coordinates[c1], coordinates[c2] = coordinates[c2], coordinates[c1] return coordinates def generate_neighbourhood(coordinates): indices = list(range(1,(len(coordinates)-1))) swaps = list(itertools.combinations(indices, 2)) neighbourhood = [swap_coordinates(coordinates, s).copy() for s in swaps] return neighbourhood def generate_random_solutions(coordinates, tabu_list): num_shuffled = math.factorial(len(coordinates))/(math.factorial(len(coordinates)-2)*2) shuffled = [] for _ in range((int(num_shuffled))): s = [coordinates[0]] + random.sample(coordinates[1:-1], len(coordinates[1:-1])) + [coordinates[-1]] if str(s) not in tabu_list: shuffled.append(s) return shuffled def find_distance(c1, c2): return ((c1[0] - c2[0])**2 + (c1[1] - c2[1])**2)**(1/2) def find_total_distance(coordinates): total_distance = 0 for i in range(1, len(coordinates)): total_distance += find_distance(coordinates[i-1], coordinates[i]) return total_distance def objective_function(coordinates): return find_total_distance(coordinates) def check_termination_criteria(total_iterations, k): if k &gt; total_iterations: return True return False def tabu_search(num_cities=4, total_iterations=1_000, display=True): initial_solution = generate_first_solution(num_cities) neighbourhood_solution = initial_solution termination_criteria = False k_iter = 0 # iteration cycle tabu_list = {str(neighbourhood_solution): 1} tabu_tenure = int(math.sqrt(total_iterations)) frequency_memory = {str(neighbourhood_solution): 1} best_solution = neighbourhood_solution best_objective_val = math.inf while not termination_criteria: # update iteration k_iter += 1 # restart diversification (fm value is arbitrary) if frequency_memory[str(neighbourhood_solution)] &gt; 10: neighbours = generate_random_solutions(initial_solution, tabu_list) neighbourhood_solution = neighbours[0] else: # initialize best neighbouring objective value and generate neighbours neighbourhood_objective_val = objective_function(neighbourhood_solution) neighbours = generate_neighbourhood(neighbourhood_solution) # iterate each neighbour for n in neighbours: current_objective_val = objective_function(n) # find the best neighbour objective value that is not tabu # we&#39;re assuming we want to minimize the objective value in this scenario if (str(n) not in tabu_list) and (current_objective_val &lt; neighbourhood_objective_val): neighbourhood_objective_val = current_objective_val neighbourhood_solution = n # aspiration criteria (best solution obtained so far) if current_objective_val &lt; best_objective_val: best_objective_val = current_objective_val best_solution = n # update tabu list for k,v in list(tabu_list.items()): tabu_list[k] += 1 if tabu_list[k] == tabu_tenure: del tabu_list[k] # add best neighbourhood solution to track frequency memory if str(neighbourhood_solution) in frequency_memory: frequency_memory[str(neighbourhood_solution)] += 1 else: frequency_memory[str(neighbourhood_solution)] = 1 # add best neighbourhood solution to tabu list tabu_list[str(neighbourhood_solution)] = 1 # check if termination criteria has been met yet if check_termination_criteria(total_iterations, k_iter): termination_criteria = True if display and k_iter % (total_iterations//10) == 0: print(f&quot;Iteration: {k_iter}&quot;) print(f&quot;Best Objective Value: {best_objective_val:.2f}&quot;) print(f&quot;Best Neighbourhood Objective Value: {neighbourhood_objective_val:.2f}&quot;) if display: print(initial_solution) plt.scatter(*zip(*(initial_solution))) plt.plot(*zip(*(initial_solution))) plt.title(&#39;Initial Solution&#39;) plt.xlabel(&#39;X Coordinate&#39;) plt.ylabel(&#39;Y Coordinate&#39;) plt.show() for k,v in frequency_memory.items(): if (v == 10) and (k != best_solution): restart_solution = ast.literal_eval(k) break print(&#39;Without Restart Diversification&#39;) print(restart_solution) plt.scatter(*zip(*(restart_solution))) plt.plot(*zip(*(restart_solution))) plt.title(&#39;Global Optima&#39;) plt.xlabel(&#39;X Coordinate&#39;) plt.ylabel(&#39;Y Coordinate&#39;) plt.show() print(&quot;Best Solution&quot;) print(best_solution) plt.scatter(*zip(*(best_solution))) plt.plot(*zip(*(best_solution))) plt.title(&#39;Best Solution&#39;) plt.xlabel(&#39;X Coordinate&#39;) plt.ylabel(&#39;Y Coordinate&#39;) plt.show() . tabu_search(num_cities=12, total_iterations=100, display=True) . Iteration: 10 Best Objective Value: 31.65 Best Neighbourhood Objective Value: 31.65 Iteration: 20 Best Objective Value: 31.65 Best Neighbourhood Objective Value: 31.65 Iteration: 30 Best Objective Value: 31.65 Best Neighbourhood Objective Value: 47.50 Iteration: 40 Best Objective Value: 31.65 Best Neighbourhood Objective Value: 33.48 Iteration: 50 Best Objective Value: 31.65 Best Neighbourhood Objective Value: 33.48 Iteration: 60 Best Objective Value: 31.65 Best Neighbourhood Objective Value: 39.79 Iteration: 70 Best Objective Value: 27.22 Best Neighbourhood Objective Value: 27.22 Iteration: 80 Best Objective Value: 27.22 Best Neighbourhood Objective Value: 27.22 Iteration: 90 Best Objective Value: 27.22 Best Neighbourhood Objective Value: 36.77 Iteration: 100 Best Objective Value: 27.22 Best Neighbourhood Objective Value: 32.15 [(6.39, 0.25), (3.4, 1.55), (8.06, 6.98), (8.09, 0.06), (2.2, 5.89), (6.5, 5.45), (0.27, 1.99), (2.19, 5.05), (4.22, 0.3), (8.92, 0.87), (7.36, 6.77), (2.75, 2.23), (6.39, 0.25)] . without restart diversification restart diversification [(6.39, 0.25), (8.09, 0.06), (8.92, 0.87), (6.5, 5.45), (8.06, 6.98), (7.36, 6.77), (2.2, 5.89), (0.27, 1.99), (2.19, 5.05), (2.75, 2.23), (3.4, 1.55), (4.22, 0.3), (6.39, 0.25)] . Best Solution [(6.39, 0.25), (8.09, 0.06), (8.92, 0.87), (8.06, 6.98), (7.36, 6.77), (6.5, 5.45), (2.2, 5.89), (2.19, 5.05), (0.27, 1.99), (2.75, 2.23), (3.4, 1.55), (4.22, 0.3), (6.39, 0.25)] . It looks like our solution works! In the second plot, we can see that our solution reaches a local optima and is stuck at that solution. This is a great example of why we need restart diversification to generate new a new neighbourhood. After performing a restart, the solution seems to converge at a global optima and we&#39;re able to find a better optima! . References . [1] F. Glover, E. Taillard and E. Taillard, &quot;A user&#39;s guide to tabu search&quot;, Annals of Operations Research, vol. 41, no. 1, pp. 1-28, 1993. Available: 10.1007/bf02078647. [2] F. Glover, &quot;Tabu Search: A Tutorial&quot;, Interfaces, vol. 20, no. 4, pp. 74-94, 1990. Available: 10.1287/inte.20.4.74. .",
            "url": "https://evandros-ks.github.io/fastblog/2022/01/13/Tabu_Search.html",
            "relUrl": "/2022/01/13/Tabu_Search.html",
            "date": " • Jan 13, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "SIR Model of Infectious Diseases",
            "content": "Background . Epidemiological models are a type of compartmental model describing disease dynamics on a population. In the case of infectious diseases, we model how the virus/disease interacts with each compartment of the system. Each compartment in this model is represented as a homogeneous system - or an individual within a population where each individual is equivalent. Different epidemiological models consider different compartments with the most common being the SIR model. The compartments in this model are categorized within the population as: . (S)usceptible | (I)nfected | (R)ecovered | . SIR Model . For our case, we&#39;ll be reviewing how to implement a discrete SIR model which describes the dynamics of the SIR compartments in discrete time intervals. This simple model allows only two possible state transitions: $ S rightarrow I $ and $I rightarrow R $. The rate of susceptible individuals becoming infected is described by ${ beta}$, the average number of contacts per individual per unit time and the recovery rate $ gamma$ described the rate for infected individuals to recover. The recovery rate $ gamma$ can also be thought as the inverse of the infectious period for an infected individual or inverse of the recovery period for an infected individual. Each state transition and scaling parameter is shown in the figure below. . Our model will also assume a closed system assuming no immigration, emigration, births, or deaths in the population. Therefore, the population, $N$, remains constant which gives us the following relation ($ ref{pop}$) for all the compartments at any time $t$. . $ N = S(t) + I(t) + R(t) label{pop} tag{1}$ . Given this relation ($ ref{pop}$), we must also consider how individuals switch states from the current time $t$ to the next day $t+1$. The number of recovered individuals ($ ref{rec}$) is simply dependent on the number of infected individuals that recover given the recovery rate $ gamma$. From this relation, we know the number of infected individuals is conditional on the outflow of recovered individuals and inflow of newly infected individuals ($ ref{inf}$). The outflow was previously described ($ ref{rec}$) based on the recovery rate while the inflow is scaled by the force of infection, $ beta I(t)$ representing the number of newly infected individuals from the susceptible population. Finally, the number of susceptible individuals can be described as the remaining individuals that have not been infected or recovered ($ ref{sus}$). . $ R(t+1) = R(t) + gamma I(t) label{rec} tag{2}$ $ I(t+1) = I(t) - gamma I(t) + beta I(t) S(t) label{inf} tag{3}$ $ S(t+1) = N - I(t+1) - R(t+1) label{sus} tag{4}$ . Code . import numpy as np import plotly.graph_objects as go import time from ipywidgets import interact, widgets, HTML . def simulate(beta: float = 0.001, infectious_period: int = 21, N: int = 100, days: int = 365): &quot;&quot;&quot;Simulates SIR model for an infectious disease. Args: beta: Transmission rate of disease per day. infectious_period: Number of days disease is transmissible for an infected individual. N: Size of population. days: Number of days to simulate disease spread not including t=0 (t=0 is when first patient is infected). Returns: S: Numpy array containing number of susceptible individuals for each discrete time point. I: Numpy array containing number of infected individuals for each discrete time point. R: Numpy array containing number of recovered individuals for each discrete time point. &quot;&quot;&quot; gamma = 1/infectious_period # Number of days to simulate (starting at t=0) days = days + 1 # Initial number of infected and recovered (t=0) I, R = np.zeros(days), np.zeros(days) I[0], R[0] = 1, 0 # Initial number of susceptible S = np.zeros(days) S[0] = N - I[0] - R[0] for t in range(days-1): R[t+1] = min(R[t] + gamma * I[t], N) I[t+1] = min(I[t] - gamma * I[t] + beta * I[t] * S[t], N) S[t+1] = max(N - I[t+1] - R[t+1], 0) return S, I, R, N def plot(S, I, R, N): fig = go.FigureWidget() fig.add_trace(go.Scatter(y=S/N, mode=&#39;lines&#39;, name=&#39;Susceptible&#39;)) fig.add_trace(go.Scatter(y=I/N, mode=&#39;lines&#39;, name=&#39;Infected&#39;)) fig.add_trace(go.Scatter(y=R/N, mode=&#39;lines&#39;, name=&#39;Recoverd&#39;)) fig.update_layout(title=&quot;SIR Model&quot;, title_x = 0.5, xaxis_title=&quot;Number of Days&quot;, yaxis_title=&quot;Percentage of Population (N)&quot;, ) return fig S, I, R, N = simulate() fig = plot(S, I, R, N) def update_params(**kwargs): S, I, R, N = simulate(**kwargs) print(kwargs) fig.data[0].y = S/N fig.data[1].y = I/N fig.data[2].y = R/N time.sleep(1/2) fig.show() interact(update_params, beta = widgets.FloatSlider(value=0.001, min=1/1_000, max=1/10, step=0.0001, readout_format=&#39;.4f&#39;), infectious_period = widgets.FloatSlider(value=21, min=1, max=100, step=1), N = widgets.IntSlider(value=100, min=0, max=10_000, step=1), days = widgets.IntSlider(value=365, min=0, max=365*2, step=1)) . &lt;function __main__.update_params(**kwargs)&gt; . Note: To view an interactive SIR plot and how each parameter ($ beta$, $ gamma$, $N$, and number of days $T$) affect the compartment dynamics click the Google Colab link at the top of the page. . Reference . Krickeberg, K., &amp; Pham, T. M. H. (2011). Epidemiology: Key to prevention. Springer Science &amp; Business Media. .",
            "url": "https://evandros-ks.github.io/fastblog/2021/12/21/SIR_Model.html",
            "relUrl": "/2021/12/21/SIR_Model.html",
            "date": " • Dec 21, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://evandros-ks.github.io/fastblog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://evandros-ks.github.io/fastblog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}